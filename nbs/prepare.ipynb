{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_prep\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import yaml\n",
    "from typing import Union, Final\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "LINE_FEAT_NAMES: Final[list[str]] = [\n",
    "    \"row\",\n",
    "    \"txt_len\",\n",
    "    \"end_with_end_sent\",\n",
    "    \"end_with_hyphen\",\n",
    "    \"start_with_upper\",\n",
    "    \"start_with_bullet\",\n",
    "    \"line_txt\",\n",
    "    \"diff_len_prev\",\n",
    "    \"diff_max_len\",\n",
    "]\n",
    "\n",
    "\n",
    "def create_line_features(lines: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"compute features for each lines in a group (doc) and return a dataframe with them\n",
    "\n",
    "    Arguments:\n",
    "        lines -- list of lines used to compute features\n",
    "\n",
    "    Returns:\n",
    "        the dataframe with the features.\n",
    "    \"\"\"\n",
    "    line_lengths = [len(l) for l in lines]\n",
    "    line_rows = [i for i, _ in enumerate(lines)]\n",
    "    are_end_of_sent = [l.strip()[-1] in [\".\", \"?\", \"!\"] if len(l.strip()) > 0 else False for l in lines]\n",
    "    are_end_hyphen = [l.strip()[-1] in [\"-\"] if len(l.strip()) > 0 else False for l in lines]\n",
    "    # erreur car élimine des lignes. ils doit avoir une valeur else\n",
    "    are_start_upper = [l.strip()[0].isupper() if len(l.strip()) > 0 else False for l in lines]\n",
    "    are_start_bullet = [l.strip().startswith((\"-\", \"•\", \"o \")) if len(l.strip()) > 0 else False for l in lines]\n",
    "\n",
    "    assert (\n",
    "        len(line_lengths)\n",
    "        == len(line_rows)\n",
    "        == len(are_end_of_sent)\n",
    "        == len(are_end_hyphen)\n",
    "        == len(are_start_upper)\n",
    "        == len(are_start_bullet)\n",
    "    ), \"all lines must be processed.\"\n",
    "\n",
    "    lines_data = [\n",
    "        (r, l, e, h, u, b, t)\n",
    "        for r, t, l, e, h, u, b in zip(\n",
    "            line_rows,\n",
    "            lines,\n",
    "            line_lengths,\n",
    "            are_end_of_sent,\n",
    "            are_end_hyphen,\n",
    "            are_start_upper,\n",
    "            are_start_bullet,\n",
    "        )\n",
    "    ]\n",
    "    lines_df = pd.DataFrame(\n",
    "        lines_data,\n",
    "        columns=[\n",
    "            \"row\",\n",
    "            \"txt_len\",\n",
    "            \"end_with_end_sent\",\n",
    "            \"end_with_hyphen\",\n",
    "            \"start_with_upper\",\n",
    "            \"start_with_bullet\",\n",
    "            \"line_txt\",\n",
    "        ],\n",
    "    )\n",
    "    lines_df[\"diff_len_prev\"] = lines_df.txt_len.diff()\n",
    "    lines_df.diff_len_prev = lines_df.diff_len_prev.fillna(lines_df.txt_len)\n",
    "    lines_df[\"diff_max_len\"] = lines_df.txt_len.max() - lines_df.txt_len\n",
    "\n",
    "    return lines_df\n",
    "\n",
    "\n",
    "def prepare_train_data_grp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Training data provides examples of sequences of text lines. Each lines belongs to a group, which is like a document.\n",
    "    This function process one group.\n",
    "\n",
    "    Arguments:\n",
    "        df -- dataframe of training lines without any features.\n",
    "\n",
    "    Returns:\n",
    "        a dataframe of a group.\n",
    "    \"\"\"\n",
    "    lines = df.line_txt.values.tolist()\n",
    "    lines_feats_df = create_line_features(lines)\n",
    "    prepared_df = pd.concat([lines_feats_df, df.new_paragraph.reset_index().new_paragraph], axis=1)\n",
    "    return prepared_df\n",
    "\n",
    "\n",
    "def prepare_train_data(lines_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Prepare raw train data and create features\n",
    "\n",
    "    Arguments:\n",
    "        lines_df -- raw train data\n",
    "\n",
    "    Returns:\n",
    "        a Dataframe of line features.\n",
    "    \"\"\"\n",
    "    lines_df[\"line_txt\"] = lines_df.line_txt.fillna(\"\")\n",
    "    df = lines_df.groupby(\"grp\").apply(prepare_train_data_grp).reset_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def prepare_data_from_csv(file_path: Union[str, Path]) -> pd.DataFrame:\n",
    "    lines_df = pd.read_csv(file_path, sep=\";\")\n",
    "    df = prepare_train_data(lines_df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_data_from_csv(Path(\"../data/train.csv\"))\n",
    "test_df = prepare_data_from_csv(\"../data/test.csv\")\n",
    "assert len(train_df) == len(train_df), \"Line nb in train should be the same\"\n",
    "assert len(test_df) == len(test_df), \"Line nb in test should be the same\"\n",
    "assert len(train_df[train_df.new_paragraph.isna()]) == 0, \"there should be no NA target value in training data\"\n",
    "assert len(test_df[test_df.new_paragraph.isna()]) == 0, \"there should be no NA target value in test data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def prepare_data_from_doc(file_path: Union[str, Path]) -> pd.DataFrame:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines: list[str] = f.read().split(\"\\n\")\n",
    "        line_feats = create_line_features(lines)\n",
    "    return line_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = prepare_data_from_doc(Path(\"../test_data/doc_a.txt\"))\n",
    "assert all([c in LINE_FEAT_NAMES for c in prep_df.columns.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export(\"prepare.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
