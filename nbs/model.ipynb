{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_line_features(lines: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"compute features for each lines in a group (doc) and return a dataframe with them\n",
    "\n",
    "    Arguments:\n",
    "        lines -- list of lines used to compute features\n",
    "\n",
    "    Returns:\n",
    "        the dataframe with the features.\n",
    "    \"\"\"\n",
    "    line_lengths = [len(l) for l in lines]\n",
    "    line_rows = [i for i, _ in enumerate(lines)]\n",
    "    are_end_of_sent = [l.strip()[-1] in [\".\", \"?\", \"!\"] if len(l.strip()) > 0 else False for l in lines]\n",
    "    are_end_hyphen = [l.strip()[-1] in [\"-\"] if len(l.strip()) > 0 else False for l in lines]\n",
    "    # erreur car élimine des lignes. ils doit avoir une valeur else\n",
    "    are_start_upper = [l.strip()[0].isupper() if len(l.strip()) > 0 else False for l in lines]\n",
    "    are_start_bullet = [l.strip().startswith((\"-\", \"•\", \"o \")) if len(l.strip()) > 0 else False for l in lines]\n",
    "\n",
    "    assert (\n",
    "        len(line_lengths)\n",
    "        == len(line_rows)\n",
    "        == len(are_end_of_sent)\n",
    "        == len(are_end_hyphen)\n",
    "        == len(are_start_upper)\n",
    "        == len(are_start_bullet)\n",
    "    ), \"all lines must be processed.\"\n",
    "\n",
    "    lines_data = [\n",
    "        (r, l, e, h, u, b, t)\n",
    "        for r, t, l, e, h, u, b in zip(\n",
    "            line_rows,\n",
    "            lines,\n",
    "            line_lengths,\n",
    "            are_end_of_sent,\n",
    "            are_end_hyphen,\n",
    "            are_start_upper,\n",
    "            are_start_bullet,\n",
    "        )\n",
    "    ]\n",
    "    lines_df = pd.DataFrame(\n",
    "        lines_data,\n",
    "        columns=[\n",
    "            \"row\",\n",
    "            \"txt_len\",\n",
    "            \"end_with_end_sent\",\n",
    "            \"end_with_hyphen\",\n",
    "            \"start_with_upper\",\n",
    "            \"start_with_bullet\",\n",
    "            \"line_txt\",\n",
    "        ],\n",
    "    )\n",
    "    lines_df[\"diff_len_prev\"] = lines_df.txt_len.diff()\n",
    "    lines_df.diff_len_prev = lines_df.diff_len_prev.fillna(lines_df.txt_len)\n",
    "    lines_df[\"diff_max_len\"] = lines_df.txt_len.max() - lines_df.txt_len\n",
    "\n",
    "    return lines_df\n",
    "\n",
    "\n",
    "def do_prepare_train_data_grp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Training data provides examples of sequences of text lines. Each lines belongs to a group, which is like a document.\n",
    "    This function process one group.\n",
    "\n",
    "    Arguments:\n",
    "        df -- dataframe of training lines without any features.\n",
    "\n",
    "    Returns:\n",
    "        a dataframe of a group.\n",
    "    \"\"\"\n",
    "    lines = df.line_txt.values.tolist()\n",
    "    lines_feats_df = create_line_features(lines)\n",
    "    prepared_df = pd.concat([lines_feats_df, df.new_paragraph.reset_index().new_paragraph], axis=1)\n",
    "    return prepared_df\n",
    "\n",
    "\n",
    "def prepare_train_data(lines_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Prepare raw train data and create features\n",
    "\n",
    "    Arguments:\n",
    "        lines_df -- raw train data\n",
    "\n",
    "    Returns:\n",
    "        a Dataframe of line features.\n",
    "    \"\"\"\n",
    "    lines_df[\"line_txt\"] = lines_df.line_txt.fillna(\"\")\n",
    "    df = lines_df.groupby(\"grp\").apply(do_prepare_train_data_grp).reset_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines_df = pd.read_csv(\"../data/train.csv\", sep=\";\")\n",
    "test_lines_df = pd.read_csv(\"../data/test.csv\", sep=\";\")\n",
    "train_df = prepare_train_data(train_lines_df)\n",
    "test_df = prepare_train_data(test_lines_df)\n",
    "assert len(train_df) == len(train_lines_df), \"Line nb in train should be the same\"\n",
    "assert len(test_df) == len(test_lines_df), \"Line nb in test should be the same\"\n",
    "assert len(train_df[train_df.new_paragraph.isna()]) == 0, \"there should be no NA target value in training data\"\n",
    "assert len(test_df[test_df.new_paragraph.isna()]) == 0, \"there should be no NA target value in test data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from typing import Final\n",
    "\n",
    "X_COLS: Final[list[str]] = [\n",
    "    \"txt_len\",\n",
    "    \"end_with_end_sent\",\n",
    "    \"end_with_hyphen\",\n",
    "    \"start_with_upper\",\n",
    "    \"start_with_bullet\",\n",
    "    \"diff_len_prev\",\n",
    "    \"diff_max_len\",\n",
    "]\n",
    "\n",
    "\n",
    "def df_to_x_y(train_df) -> tuple[np.ndarray, np.ndarray]:\n",
    "    y_col = \"new_paragraph\"\n",
    "    x = train_df[X_COLS]\n",
    "    y = train_df[y_col]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def cross_validate_model(clf: BaseEstimator, train_df: pd.DataFrame, cv: int = 3) -> list[float]:\n",
    "    x, y = df_to_x_y(train_df)\n",
    "    return cross_val_score(clf, x, y, cv=cv).tolist()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelScores:\n",
    "    cv_scores: list[float]\n",
    "    train_accuracy: float\n",
    "    test_accuracy: float\n",
    "\n",
    "\n",
    "def save_experiment(clf: BaseEstimator, scores: ModelScores, model_name: str, version: str):\n",
    "    exp_dir: Path = Path(\"../experiments\") / model_name / version\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "    # os.makedirs(exp_dir, exist_ok=True)\n",
    "    joblib.dump(clf, exp_dir / \"clf.joblib\")\n",
    "    metadata = dict(\n",
    "        {\n",
    "            \"name\": model_name,\n",
    "            \"version\": version,\n",
    "            \"cv_scores\": scores.cv_scores,\n",
    "            \"train_accuracy\": scores.train_accuracy,\n",
    "            \"test_accuracy\": scores.test_accuracy,\n",
    "            \"hparams\": clf.get_params(),\n",
    "        }\n",
    "    )\n",
    "    with open(exp_dir / \"metadata.yaml\", \"w\") as f:\n",
    "        yaml.dump(metadata, f, sort_keys=False)\n",
    "\n",
    "\n",
    "def save_model(clf: BaseEstimator):\n",
    "    model_dir = Path(\"../model\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    joblib.dump(clf, model_dir / \"clf.joblib\")\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    clf: BaseEstimator, train_df: pd.DataFrame, test_df: pd.DataFrame, model_name: str, version: str, cv: int = 3\n",
    ") -> BaseEstimator:\n",
    "    cv_scores = cross_validate_model(clf, train_df, cv=cv)\n",
    "    x_train, y_train = df_to_x_y(train_df)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    x_test, y_test = df_to_x_y(test_df)\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    scores = ModelScores(cv_scores=cv_scores, train_accuracy=train_accuracy, test_accuracy=test_accuracy)\n",
    "    save_experiment(clf, scores, model_name, version)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage experiments with diff models and then select the best one which is put into model.\n",
    "clf = train_model(GradientBoostingClassifier(), train_df, test_df, model_name=\"xg\", version=\"1.0\", cv=3)\n",
    "\n",
    "# save_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model_dir = Path(\"../model\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "tto: Path = model_dir / \"clf.joblib\"\n",
    "\n",
    "dump(clf, Path(\"../model/clf.joblib\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "cross_val_score(clf, x, y, cv=3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train_model(train_df)\n",
    "x, y = df_to_x_y(train_df)\n",
    "clf.score(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = df_to_x_y(test_df)\n",
    "clf.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def load_model(version: str) -> ClassifierMixin:\n",
    "    clf = load(f\"../models/paragraph_clf/{version}/clf.joblib\")\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lclf = load_model(\"1.0\")\n",
    "lclf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def prepare_paragraph_from_txt_lines(clf: ClassifierMixin, lines: list[str]) -> str:\n",
    "    lines_df = create_line_features(lines)\n",
    "    x = lines_df[X_COLS]\n",
    "    preds = clf.predict(x).tolist()\n",
    "    txt = \"\"\n",
    "    for l, pred in zip(lines, preds):\n",
    "        if len(l) > 0:\n",
    "            if l[-1] == \"-\":\n",
    "                l = l[:-1]\n",
    "\n",
    "        if pred == 1:\n",
    "            txt += \"\\n\" + l\n",
    "        else:\n",
    "            txt += l\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prepare_paragraph_from_txt_lines(clf, train_lines_df.line_txt.values.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export(\"core.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
