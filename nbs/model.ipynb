{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.base import ClassifierMixin\n",
    "from joblib import dump, load\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def create_line_features(lines: list[str]) -> pd.DataFrame:\n",
    "    line_lengths = [len(l) for l in lines]\n",
    "    line_rows = [i for i, _ in enumerate(lines)]\n",
    "    are_end_of_sent = [l.strip()[-1] in [\".\", \"?\", \"!\"] if len(l.strip()) > 0 else False for l in lines]\n",
    "    are_end_hyphen = [l.strip()[-1] in [\"-\"] if len(l.strip()) > 0 else False for l in lines]\n",
    "    # erreur car élimine des lignes. ils doit avoir une valeur else\n",
    "    are_start_upper = [l.strip()[0].isupper() if len(l.strip()) > 0 else False for l in lines]\n",
    "    are_start_bullet = [l.strip().startswith((\"-\", \"•\", \"o \")) if len(l.strip()) > 0 else False for l in lines]\n",
    "\n",
    "    # print(all_lines)\n",
    "    lines_data = [\n",
    "        (r, l, e, h, u, b, t)\n",
    "        for r, t, l, e, h, u, b in iter(\n",
    "            zip(\n",
    "                line_rows,\n",
    "                lines,\n",
    "                line_lengths,\n",
    "                are_end_of_sent,\n",
    "                are_end_hyphen,\n",
    "                are_start_upper,\n",
    "                are_start_bullet,\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "    lines_df = pd.DataFrame(\n",
    "        lines_data,\n",
    "        columns=[\n",
    "            \"row\",\n",
    "            \"txt_len\",\n",
    "            \"end_with_end_sent\",\n",
    "            \"end_with_hyphen\",\n",
    "            \"start_with_upper\",\n",
    "            \"start_with_bullet\",\n",
    "            \"line_txt\",\n",
    "        ],\n",
    "    )\n",
    "    lines_df[\"diff_len_prev\"] = lines_df.txt_len.diff()\n",
    "    lines_df.diff_len_prev = lines_df.diff_len_prev.fillna(lines_df.txt_len)\n",
    "    lines_df[\"diff_max_len\"] = lines_df.txt_len.max() - lines_df.txt_len\n",
    "\n",
    "    return lines_df\n",
    "\n",
    "\n",
    "def do_prepare_train_data_grp(df: pd.DataFrame):\n",
    "    lines = df.line_txt.values.tolist()\n",
    "    lines_feats_df = create_line_features(lines)\n",
    "    prepared_df = pd.concat([lines_feats_df, df.new_paragraph.reset_index().new_paragraph], axis=1)\n",
    "    return prepared_df\n",
    "\n",
    "\n",
    "def prepare_train_data(lines_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    lines_df[\"line_txt\"] = lines_df.line_txt.fillna(\"\")\n",
    "    df = lines_df.groupby(\"grp\").apply(do_prepare_train_data_grp).reset_index()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines_df = pd.read_csv(\"../data/train.csv\", sep=\";\")\n",
    "train_df = prepare_train_data(train_lines_df)\n",
    "assert len(train_df) == len(train_lines_df), \"Line nb should be the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from typing import Final\n",
    "\n",
    "X_COLS: Final[list[str]] = [\n",
    "    \"txt_len\",\n",
    "    \"end_with_end_sent\",\n",
    "    \"end_with_hyphen\",\n",
    "    \"start_with_upper\",\n",
    "    \"start_with_bullet\",\n",
    "    \"diff_len_prev\",\n",
    "    \"diff_max_len\",\n",
    "]\n",
    "\n",
    "\n",
    "def df_to_x_y(train_df) -> tuple[np.ndarray, np.ndarray]:\n",
    "    y_col = \"new_paragraph\"\n",
    "    x = train_df[X_COLS]\n",
    "    y = train_df[y_col]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train_model(train_df: pd.DataFrame, version: str = \"1.0\") -> ClassifierMixin:\n",
    "    x, y = df_to_x_y(train_df)\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    model_dir = f\"../models/paragraph_clf/{version}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    dump(clf, f\"{model_dir}/clf.joblib\")\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train_model(train_df, version=\"1.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df_to_x_y(train_df)\n",
    "clf.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def load_model(version: str) -> ClassifierMixin:\n",
    "    clf = load(f\"../models/paragraph_clf/{version}/clf.joblib\")\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lclf = load_model(\"1.0\")\n",
    "lclf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def prepare_paragraph_from_txt_lines(clf: ClassifierMixin, lines: list[str]) -> str:\n",
    "    lines_df = create_line_features(lines)\n",
    "    x = lines_df[X_COLS]\n",
    "    preds = clf.predict(x).tolist()\n",
    "    txt = \"\"\n",
    "    for l, pred in zip(lines, preds):\n",
    "        if len(l) > 0:\n",
    "            if l[-1] == \"-\":\n",
    "                l = l[:-1]\n",
    "\n",
    "        if pred == 1:\n",
    "            txt += \"\\n\" + l\n",
    "        else:\n",
    "            txt += l\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prepare_paragraph_from_txt_lines(clf, train_lines_df.line_txt.values.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export(\"core.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
