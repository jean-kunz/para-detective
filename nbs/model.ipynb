{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from paragraph_detective.data_prep import prepare_data_from_csv, prepare_data_from_doc, create_line_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from typing import Final\n",
    "\n",
    "MODEL_FILE_NAME: Final[str] = \"clf.joblib\"\n",
    "X_COLS: Final[list[str]] = [\n",
    "    \"txt_len\",\n",
    "    \"end_with_end_sent\",\n",
    "    \"end_with_hyphen\",\n",
    "    \"start_with_upper\",\n",
    "    \"start_with_bullet\",\n",
    "    \"diff_len_prev\",\n",
    "    \"diff_max_len\",\n",
    "]\n",
    "\n",
    "\n",
    "def df_to_x_y(train_df) -> tuple[np.ndarray, np.ndarray]:\n",
    "    y_col = \"new_paragraph\"\n",
    "    x = train_df[X_COLS]\n",
    "    y = train_df[y_col]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def cross_validate_model(clf: BaseEstimator, train_df: pd.DataFrame, cv: int = 3) -> list[float]:\n",
    "    x, y = df_to_x_y(train_df)\n",
    "    return cross_val_score(clf, x, y, cv=cv).tolist()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelScores:\n",
    "    cv_scores: list[float]\n",
    "    train_accuracy: float\n",
    "    test_accuracy: float\n",
    "\n",
    "\n",
    "def save_experiment(clf: BaseEstimator, scores: ModelScores, model_name: str, version: str):\n",
    "    exp_dir: Path = Path(\"../experiments\") / model_name / version\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "    joblib.dump(clf, exp_dir / MODEL_FILE_NAME)\n",
    "    metadata = dict(\n",
    "        {\n",
    "            \"name\": model_name,\n",
    "            \"version\": version,\n",
    "            \"cv_scores\": scores.cv_scores,\n",
    "            \"train_accuracy\": scores.train_accuracy,\n",
    "            \"test_accuracy\": scores.test_accuracy,\n",
    "            \"hparams\": clf.get_params(),\n",
    "        }\n",
    "    )\n",
    "    with open(exp_dir / \"metadata.yaml\", \"w\") as f:\n",
    "        yaml.dump(metadata, f, sort_keys=False)\n",
    "\n",
    "\n",
    "def save_model(clf: BaseEstimator):\n",
    "    model_dir = Path(\"../model\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    joblib.dump(clf, model_dir / MODEL_FILE_NAME)\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    clf: ClassifierMixin,\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    version: str,\n",
    "    cv: int = 3,\n",
    ") -> tuple[ClassifierMixin, ModelScores]:\n",
    "    cv_scores = cross_validate_model(clf, train_df, cv=cv)\n",
    "    x_train, y_train = df_to_x_y(train_df)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    train_accuracy = float(accuracy_score(y_train, y_pred_train))\n",
    "    x_test, y_test = df_to_x_y(test_df)\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    test_accuracy = float(accuracy_score(y_test, y_pred_test))\n",
    "    scores = ModelScores(cv_scores=cv_scores, train_accuracy=train_accuracy, test_accuracy=test_accuracy)\n",
    "    save_experiment(clf, scores, model_name, version)\n",
    "    return clf, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage experiments with diff models and then select the best one which is put into model.\n",
    "train_df = prepare_data_from_csv(Path(\"../data/train.csv\"))\n",
    "test_df = prepare_data_from_csv(\"../data/test.csv\")\n",
    "clf, scores = train_model(GradientBoostingClassifier(), train_df, test_df, model_name=\"xg\", version=\"1.0\", cv=3)\n",
    "\n",
    "# save_model(clf)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def load_model() -> ClassifierMixin:\n",
    "    clf = joblib.load(Path(\"../model/clf.joblib\"))\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lclf = load_model()\n",
    "lclf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def clean_paragraph_from_txt_lines(clf: ClassifierMixin, lines: list[str]) -> str:\n",
    "    lines_df = create_line_features(lines)\n",
    "    x = lines_df[X_COLS]\n",
    "    preds = clf.predict(x).tolist()\n",
    "    txt = \"\"\n",
    "    for l, pred in zip(lines, preds):\n",
    "        if len(l) > 0:\n",
    "            if l[-1] == \"-\":\n",
    "                l = l[:-1]\n",
    "\n",
    "        # 1 is for new paragraph.\n",
    "        if pred == 1:\n",
    "            txt += \"\\n\" + l\n",
    "        else:\n",
    "            txt += l\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"../test_data/doc_a.txt\"), \"r\") as f:\n",
    "    lines: list[str] = f.read().split('\\n')\n",
    "    txt = clean_paragraph_from_txt_lines(clf, lines)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export(\"core.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
