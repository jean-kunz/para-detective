{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import joblib\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from paragraph_detective.data_prep import prepare_data_from_doc, create_line_features\n",
    "from paragraph_detective.model import MODEL_FILE_NAME, df_to_x_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data_grp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Training data provides examples of sequences of text lines. Each lines belongs to a group, which is like a document.\n",
    "    This function process one group.\n",
    "\n",
    "    Arguments:\n",
    "        df -- dataframe of training lines without any features.\n",
    "\n",
    "    Returns:\n",
    "        a dataframe of a group.\n",
    "    \"\"\"\n",
    "    lines = df.line_txt.values.tolist()\n",
    "    lines_feats_df = create_line_features(lines)\n",
    "    prepared_df = pd.concat([lines_feats_df, df.new_paragraph.reset_index().new_paragraph], axis=1)\n",
    "    return prepared_df\n",
    "\n",
    "\n",
    "def prepare_train_data(lines_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Prepare raw train data and create features\n",
    "\n",
    "    Arguments:\n",
    "        lines_df -- raw train data\n",
    "\n",
    "    Returns:\n",
    "        a Dataframe of line features.\n",
    "    \"\"\"\n",
    "    lines_df[\"line_txt\"] = lines_df.line_txt.fillna(\"\")\n",
    "    df = lines_df.groupby(\"grp\").apply(prepare_train_data_grp).reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_from_csv(file_path: Union[str, Path]) -> pd.DataFrame:\n",
    "    lines_df = pd.read_csv(file_path, sep=\";\")\n",
    "    df = prepare_train_data(lines_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_data_from_csv(Path(\"../data/train.csv\"))\n",
    "test_df = prepare_data_from_csv(\"../data/test.csv\")\n",
    "assert len(train_df) == len(train_df), \"Line nb in train should be the same\"\n",
    "assert len(test_df) == len(test_df), \"Line nb in test should be the same\"\n",
    "assert len(train_df[train_df.new_paragraph.isna()]) == 0, \"there should be no NA target value in training data\"\n",
    "assert len(test_df[test_df.new_paragraph.isna()]) == 0, \"there should be no NA target value in test data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train models experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(clf: BaseEstimator, train_df: pd.DataFrame, cv: int = 3) -> list[float]:\n",
    "    x, y = df_to_x_y(train_df)\n",
    "    return cross_val_score(clf, x, y, cv=cv).tolist()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelScores:\n",
    "    cv_scores: list[float]\n",
    "    train_accuracy: float\n",
    "    test_accuracy: float\n",
    "    train_conf_matrix: list[list[int]]\n",
    "    test_conf_matrix: list[list[int]]\n",
    "    train_recall: float\n",
    "    test_recall: float\n",
    "    train_precision: float\n",
    "    test_precision: float\n",
    "    train_f1: float\n",
    "    test_f1: float\n",
    "\n",
    "\n",
    "def get_experiment_path(name: str, version: str) -> Path:\n",
    "    return Path(\"../experiments\") / name / version\n",
    "\n",
    "\n",
    "def save_experiment(\n",
    "    clf: BaseEstimator,\n",
    "    scores: ModelScores,\n",
    "    model_name: str,\n",
    "    version: str,\n",
    "    train_error_df: pd.DataFrame,\n",
    "    test_error_df: pd.DataFrame,\n",
    ") -> None:\n",
    "    exp_dir_path = get_experiment_path(model_name, version)\n",
    "    os.makedirs(exp_dir_path, exist_ok=True)\n",
    "\n",
    "    joblib.dump(clf, exp_dir_path / MODEL_FILE_NAME)\n",
    "    metadata = dict(\n",
    "        {\n",
    "            \"name\": model_name,\n",
    "            \"version\": version,\n",
    "            \"cv_scores\": scores.cv_scores,\n",
    "            \"train_accuracy\": scores.train_accuracy,\n",
    "            \"train_confusion_matrix\": scores.train_conf_matrix,\n",
    "            \"train_f1\": scores.train_f1,\n",
    "            \"train_precision\": scores.train_precision,\n",
    "            \"train_recall\": scores.train_recall,\n",
    "            \"test_accuracy\": scores.test_accuracy,\n",
    "            \"test_confusion_matrix\": scores.test_conf_matrix,\n",
    "            \"test_f1\": scores.train_f1,\n",
    "            \"test_precision\": scores.train_precision,\n",
    "            \"test_recall\": scores.train_recall,\n",
    "            \"hparams\": clf.get_params(),\n",
    "        }\n",
    "    )\n",
    "    with open(exp_dir_path / \"metadata.yaml\", \"w\") as f:\n",
    "        yaml.dump(metadata, f, sort_keys=False)\n",
    "\n",
    "    train_error_df.to_csv(exp_dir_path / \"train_error.csv\", index=False)\n",
    "    test_error_df.to_csv(exp_dir_path / \"test_error.csv\", index=False)\n",
    "\n",
    "\n",
    "def save_model(clf: BaseEstimator):\n",
    "    model_dir = Path(\"../model\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    joblib.dump(clf, model_dir / MODEL_FILE_NAME)\n",
    "\n",
    "\n",
    "def analyze_error(data_df: pd.DataFrame, y_pred: np.ndarray) -> pd.DataFrame:\n",
    "    df = pd.concat([data_df, pd.Series(y_pred, name=\"prediction\")], axis=1)\n",
    "    error_cond = [\n",
    "        (df.new_paragraph == df.prediction) & (df.new_paragraph == 1),\n",
    "        (df.new_paragraph != df.prediction) & (df.new_paragraph == 1),\n",
    "        (df.new_paragraph == df.prediction) & (df.new_paragraph == 0),\n",
    "        (df.new_paragraph != df.prediction) & (df.new_paragraph == 0),\n",
    "    ]\n",
    "    error_cat = [\"TP\", \"FP\", \"TN\", \"FN\"]\n",
    "    df[\"error\"] = np.select(error_cond, error_cat)\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    clf: BaseEstimator,\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    version: str,\n",
    "    cv: int = 3,\n",
    ") -> tuple[BaseEstimator, ModelScores]:\n",
    "    cv_scores = cross_validate_model(clf, train_df, cv=cv)\n",
    "    x_train, y_train = df_to_x_y(train_df)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred_train = clf.predict(x_train)\n",
    "    train_accuracy = float(accuracy_score(y_train, y_pred_train))\n",
    "    train_precision = float(precision_score(y_train, y_pred_train))\n",
    "    train_recall = float(recall_score(y_train, y_pred_train))\n",
    "    train_f1 = float(f1_score(y_train, y_pred_train))\n",
    "    train_cm: list[list[int]] = confusion_matrix(y_train, y_pred_train).tolist()\n",
    "    train_error_df = analyze_error(train_df, y_pred_train)\n",
    "\n",
    "    x_test, y_test = df_to_x_y(test_df)\n",
    "    y_pred_test = clf.predict(x_test)\n",
    "    test_accuracy = float(accuracy_score(y_test, y_pred_test))\n",
    "    test_precision = float(precision_score(y_test, y_pred_test))\n",
    "    test_recall = float(recall_score(y_test, y_pred_test))\n",
    "    test_f1 = float(f1_score(y_test, y_pred_test))\n",
    "    test_cm: list[list[int]] = confusion_matrix(y_test, y_pred_test).tolist()\n",
    "    test_error_df = analyze_error(test_df, y_pred_test)\n",
    "\n",
    "    scores = ModelScores(\n",
    "        cv_scores=cv_scores,\n",
    "        train_accuracy=train_accuracy,\n",
    "        train_conf_matrix=train_cm,\n",
    "        train_recall=train_recall,\n",
    "        train_precision=train_precision,\n",
    "        train_f1=train_f1,\n",
    "        test_accuracy=test_accuracy,\n",
    "        test_conf_matrix=test_cm,\n",
    "        test_recall=test_recall,\n",
    "        test_precision=test_precision,\n",
    "        test_f1=test_f1,\n",
    "    )\n",
    "\n",
    "    save_experiment(clf, scores, model_name, version, train_error_df, test_error_df)\n",
    "    return clf, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage experiments with diff models and then select the best one which is put into model.\n",
    "models = [(\"xgb\", GradientBoostingClassifier()), (\"random_forrest\", RandomForestClassifier())]\n",
    "\n",
    "for name, model in models:\n",
    "    train_df = prepare_data_from_csv(Path(\"../data/train.csv\"))\n",
    "    test_df = prepare_data_from_csv(\"../data/test.csv\")\n",
    "    clf, scores = train_model(model, train_df, test_df, model_name=name, version=\"1.0\", cv=3)\n",
    "\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(from_experiment: bool = False, name: str = \"\", version: str = \"\") -> BaseEstimator:\n",
    "    if from_experiment:\n",
    "        exp_dir_path = get_experiment_path(name, version)\n",
    "        clf = joblib.load(exp_dir_path / MODEL_FILE_NAME)\n",
    "    else:\n",
    "        clf = joblib.load(Path(\"../model\") / MODEL_FILE_NAME)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df: pd.DataFrame):\n",
    "    clf = RandomForestClassifier()\n",
    "    x_train, y_train = df_to_x_y(train_df)\n",
    "    clf.fit(x_train, y_train)\n",
    "    save_model(clf)\n",
    "\n",
    "\n",
    "train_model(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
